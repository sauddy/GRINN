{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f1ec247-50b3-4545-abbb-742a512903dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: not using Google CoLab\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59c3c70a-54a3-46d6-b3ff-841f7b4b0eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: Windows-11-10.0.26100-SP0\n",
      "PyTorch Version: 2.6.0+cu124\n",
      "GPU is available\n",
      "MPS (Apple Metal) is NOT AVAILABLE\n",
      "Target device is cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "## TORCH IMPORTS ##\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy.fft import fft, ifft,fft2, ifft2, fftn, ifftn\n",
    "from scipy import signal\n",
    "import os\n",
    "import scipy\n",
    "import time\n",
    "\n",
    "has_gpu = torch.cuda.is_available()\n",
    "has_mps = torch.backends.mps.is_built()\n",
    "device = \"mps\" if torch.backends.mps.is_built() \\\n",
    "    else \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "# print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(\"GPU is\", \"available\" if has_gpu else \"NOT AVAILABLE\")\n",
    "print(\"MPS (Apple Metal) is\", \"AVAILABLE\" if has_mps else \"NOT AVAILABLE\")\n",
    "print(f\"Target device is {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8565e048-302a-4d4b-a99c-e3f6583ecbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sin(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return torch.sin(input)\n",
    "    \n",
    "class PINNs(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, num_layer):\n",
    "        super(PINNs, self).__init__()\n",
    "   \n",
    "\n",
    "        layers = []\n",
    "        for i in range(num_layer-1):\n",
    "            if i == 0:\n",
    "                layers.append(nn.Linear(in_features=in_dim, out_features=hidden_dim))\n",
    "                layers.append(Sin())\n",
    "                # layers.append(torch.sin(layers))\n",
    "            else:\n",
    "                layers.append(nn.Linear(in_features=hidden_dim, out_features=hidden_dim))\n",
    "                layers.append(Sin())\n",
    "\n",
    "        layers.append(nn.Linear(in_features=hidden_dim, out_features=out_dim))\n",
    "\n",
    "        self.linear = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, xy, t):\n",
    "        src = torch.cat([xy, t], dim=-1)\n",
    "        return self.linear(src)\n",
    "    \n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d45fc50-e1b7-47f8-aed2-b9c56457c90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PINNs(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=32, bias=True)\n",
      "    (1): Sin()\n",
      "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (3): Sin()\n",
      "    (4): Linear(in_features=32, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = PINNs(in_dim=3, hidden_dim=32, out_dim=4, num_layer=3).to(device) #Input dimensions increased from 2 to 3 and Output dimensions from 3 to 4 to account for the increased spatial dimension (y)\n",
    "net.apply(init_weights)\n",
    "print(net) \n",
    "mse_cost_function = torch.nn.MSELoss() # Mean squared error\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.001,)\n",
    "optimizerL = torch.optim.LBFGS(net.parameters(),line_search_fn='strong_wolfe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4140684-1653-4ca8-a9f1-05ce01595c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary_rho_vel_phi(x_bc_l, x_bc_r, y_bc_b, y_bc_t, t, net):\n",
    "    \n",
    "    # X-direction boundaries (left)\n",
    "    x_left = x_bc_l[:, 0:1].clone().requires_grad_(True)\n",
    "    y_left = x_bc_l[:, 1:2].clone().requires_grad_(True)\n",
    "    outputs_left = net(torch.cat([x_left, y_left], dim=1), t)\n",
    "    rho_x_l, vx_x_l, vy_x_l, phi_x_l = outputs_left.chunk(4, dim=1)\n",
    "\n",
    "    # X-direction boundaries (right)\n",
    "    x_right = x_bc_r[:, 0:1].clone().requires_grad_(True)\n",
    "    y_right = x_bc_r[:, 1:2].clone().requires_grad_(True)\n",
    "    outputs_right = net(torch.cat([x_right, y_right], dim=1), t)\n",
    "    rho_x_r, vx_x_r, vy_x_r, phi_x_r = outputs_right.chunk(4, dim=1)\n",
    "\n",
    "    # Y-direction boundaries (bottom)\n",
    "    x_bottom = y_bc_b[:, 0:1].clone().requires_grad_(True)\n",
    "    y_bottom = y_bc_b[:, 1:2].clone().requires_grad_(True)\n",
    "    outputs_left = net(torch.cat([x_bottom, y_bottom], dim=1), t)\n",
    "    rho_y_b, vx_y_b, vy_y_b, phi_y_b = outputs_left.chunk(4, dim=1)\n",
    "\n",
    "    # Y-direction boundaries (top)\n",
    "    x_top = y_bc_t[:, 0:1].clone().requires_grad_(True)\n",
    "    y_top = y_bc_t[:, 1:2].clone().requires_grad_(True)\n",
    "    outputs_right = net(torch.cat([x_top, y_top], dim=1), t)\n",
    "    rho_y_t, vx_y_t, vy_y_t, phi_y_t = outputs_right.chunk(4, dim=1)\n",
    "\n",
    "    # Y-direction boundaries \n",
    "    #rho_y_b, vx_y_b, vy_y_b, phi_y_b = net(torch.cat([y_bc_b[:,0:1], y_bc_b[:,1:2]], dim=1), t).chunk(4, dim=1)\n",
    "    #rho_y_t, vx_y_t, vy_y_t, phi_y_t = net(torch.cat([y_bc_t[:,0:1], y_bc_t[:,1:2]], dim=1), t).chunk(4, dim=1)\n",
    "\n",
    "    # Potential gradients\n",
    "    phi_x_l_x = torch.autograd.grad(phi_x_l, x_left, grad_outputs=torch.ones_like(phi_x_l), create_graph=True, retain_graph=True)[0]\n",
    "    phi_x_r_x = torch.autograd.grad(phi_x_r, x_right, grad_outputs=torch.ones_like(phi_x_r), create_graph=True, retain_graph=True)[0]\n",
    "    \n",
    "    phi_y_b_y = torch.autograd.grad(phi_y_b, y_bottom, grad_outputs=torch.ones_like(phi_y_b), create_graph=True, retain_graph=True)[0]\n",
    "    phi_y_t_y = torch.autograd.grad(phi_y_t, y_top, grad_outputs=torch.ones_like(phi_y_t), create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "    # Boundary residuals\n",
    "    rho_b_x = rho_x_l - rho_x_r\n",
    "    vx_b_x = vx_x_l - vx_x_r\n",
    "    vy_b_x = vy_x_l - vy_x_r\n",
    "    \n",
    "    rho_b_y = rho_y_b - rho_y_t\n",
    "    vx_b_y = vx_y_b - vx_y_t\n",
    "    vy_b_y = vy_y_b - vy_y_t\n",
    "    \n",
    "    phi_b_x = phi_x_l - phi_x_r\n",
    "    phi_b_y = phi_y_b - phi_y_t\n",
    "    \n",
    "    phi_x_b = phi_x_l_x - phi_x_r_x\n",
    "    phi_y_b = phi_y_b_y - phi_y_t_y\n",
    "\n",
    "    return rho_b_x, rho_b_y, vx_b_x, vx_b_y, vy_b_x, vy_b_y, phi_b_x, phi_b_y, phi_x_b, phi_y_b\n",
    "\n",
    "def pde_residue(x, y, t, net):\n",
    "\n",
    "    xy = torch.cat([x, y], dim=1)\n",
    "    net_outputs = net(xy, t)\n",
    "    \n",
    "    rho, v_x, v_y, phi = net_outputs[:,0:1], net_outputs[:,1:2], net_outputs[:,2:3], net_outputs[:,3:4]\n",
    "\n",
    "    rho_x = torch.autograd.grad(rho, x,grad_outputs=torch.ones_like(rho), create_graph=True)[0]\n",
    "    rho_y = torch.autograd.grad(rho, y,grad_outputs=torch.ones_like(rho), create_graph=True)[0]\n",
    "    rho_t = torch.autograd.grad(rho, t,grad_outputs=torch.ones_like(rho),create_graph=True)[0]\n",
    "\n",
    "    v_x_x = torch.autograd.grad(v_x, x,grad_outputs=torch.ones_like(v_x), create_graph=True)[0]\n",
    "    v_x_y = torch.autograd.grad(v_x, y,grad_outputs=torch.ones_like(v_x), create_graph=True)[0]\n",
    "    v_y_x = torch.autograd.grad(v_y, x,grad_outputs=torch.ones_like(v_y), create_graph=True)[0]\n",
    "    v_y_y = torch.autograd.grad(v_y, y,grad_outputs=torch.ones_like(v_y), create_graph=True)[0]\n",
    "    \n",
    "    v_x_t = torch.autograd.grad(v_x, t,grad_outputs=torch.ones_like(v_x), create_graph=True)[0]\n",
    "    v_y_t = torch.autograd.grad(v_y, t,grad_outputs=torch.ones_like(v_y), create_graph=True)[0]\n",
    "\n",
    "    phi_x = torch.autograd.grad(phi, x,grad_outputs=torch.ones_like(phi), create_graph=True)[0]\n",
    "    phi_x_x = torch.autograd.grad(phi_x, x,grad_outputs=torch.ones_like(phi_x), create_graph=True)[0]\n",
    "\n",
    "    phi_y = torch.autograd.grad(phi, y,grad_outputs=torch.ones_like(phi), create_graph=True)[0]\n",
    "    phi_y_y = torch.autograd.grad(phi_y, y,grad_outputs=torch.ones_like(phi_y), create_graph=True)[0]\n",
    "\n",
    "    rho_r = rho_t + v_x * rho_x + rho * v_x_x + v_y * rho_y + rho * v_y_y #The residue from the density equation, in the same format as in PINN-2DG\n",
    "    v_x_r = rho * v_x_t + rho * (v_x * v_x_x + v_y * v_x_y) + cs * cs * rho_x + rho * phi_x #The momentum equation in 2D in X, in the same format as in PINN-2DG\n",
    "    v_y_r = rho * v_y_t + rho * (v_y * v_y_y + v_x * v_y_x) + cs * cs * rho_y + rho * phi_y #The momentum equation in 2D in Y, in the same format as in PINN-2DG\n",
    "    phi_r = phi_x_x + phi_y_y - const * (rho - rho_o) #The residue from the Poisson equation, in the same format as in PINN-2DG\n",
    "\n",
    "    return rho_r, v_x_r, v_y_r, phi_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ed4e1d9-ca48-44c6-bbf0-3d2b80d446aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CASE 1           (refer to the paper for details)\n",
    "lam_x = 7.0           # 2*pi/lam_x = k_x\n",
    "lam_y = 7.0           # 2*pi/lam_y = k_y\n",
    "lam = lam_x*lam_y/np.sqrt(lam_x**2 + lam_y**2) # 2*pi/lam = k = sqrt((k^2 = k_x^2 + k_y^2))\n",
    "num_of_waves = 2\n",
    "rho_1a = 0.03        # question 2a linear wave propagation\n",
    "\n",
    "# ## CASE 2          (refer to the paper for details)\n",
    "#lam = 7.0          # one wavelength\n",
    "#num_of_waves = 3\n",
    "#rho_1a = 0.3        # question 2a linear wave propagation\n",
    "\n",
    "# ## CASE 2          (refer to the paper for details)\n",
    "#lam = 5.0          # one wavelength\n",
    "#num_of_waves = 3\n",
    "#rho_1a = 0.03       # question 2a linear wave propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b5a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PROBLEM CONSTANTS ####\n",
    "rho_o = 1          ## zeroth order density\n",
    "cs = 1.0           ##  Sound Speed\n",
    "const = 1          ## we set 4 pi G  to 1\n",
    "G = 1\n",
    "\n",
    "output_folder = \"1D_fig\" \n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "    \n",
    "################ THE ANALYTIC MODEL ####################\n",
    "  \n",
    "\n",
    "jeans = np.sqrt(4*np.pi**2*cs**2/(const*G*rho_o)) #jeans length in GRINN paper\n",
    "\n",
    "if lam_x > jeans:\n",
    "    alpha_x = np.sqrt(const*rho_o-cs**2*(2*np.pi/lam_x)**2)\n",
    "else:\n",
    "    alpha_x = np.sqrt(cs**2*(2*np.pi/lam_x)**2 - const*rho_o)\n",
    "\n",
    "if lam_y > jeans:\n",
    "    alpha_y = np.sqrt(const*rho_o-cs**2*(2*np.pi/lam_y)**2)\n",
    "else:\n",
    "    alpha_y = np.sqrt(cs**2*(2*np.pi/lam_y)**2 - const*rho_o)\n",
    "\n",
    "# v_1a = (cs*rho_1a)/rho_o ## velocity perturbation without gravity\n",
    "\n",
    "v_1ax = ((cs*2/rho_o) - (const*lam**2/4*np.pi**2)) * (rho_1a/alpha_x)*(2*np.pi/lam_x) # With gravity in x\n",
    "\n",
    "v_1ay = ((cs*2/rho_o) - (const*lam**2/4*np.pi**2)) * (rho_1a/alpha_y)*(2*np.pi/lam_y) # With gravity in y\n",
    "\n",
    "def fun_rho_0(x, y):\n",
    "    ''' Define initial condition for density Returning Eq (11a)'''\n",
    "    print('wavelength',lam)\n",
    "    rho_0 = rho_o + rho_1a * np.cos((2*np.pi*x/lam_x) + (2*np.pi*x/lam_y))\n",
    "    return rho_0\n",
    "\n",
    "def fun_v_0(x, y):\n",
    "    '''initial condition for velocity -- Returning Eq 11b'''\n",
    "    \n",
    "    if lam > jeans:\n",
    "        v_0 = - v_1ax * np.sin(2*np.pi*x/lam_x) - v_1ay * np.sin(2*np.pi*y/lam_y)  ## This is for sound wave ## refer to the paper for details\n",
    "    else:\n",
    "        v_0 = v_1ax * np.cos(2*np.pi*x/lam_x) + v_1ay * np.cos(2*np.pi*y/lam_y) ## This is for the gravity wave\n",
    "    return v_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f35fa2c2-e17b-41fa-92f8-32ae08361fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wavelength 4.949747468305833\n",
      "torch.Size([30000, 1])\n"
     ]
    }
   ],
   "source": [
    "## TIME & SPACE\n",
    "tmin = 0.\n",
    "tmax = 1.\n",
    "\n",
    "xmin = 0.\n",
    "xmax = xmin+lam*num_of_waves\n",
    "\n",
    "ymin = 0.\n",
    "ymax = ymin+lam*num_of_waves\n",
    "\n",
    "cs = 1.\n",
    "\n",
    "### NUMBER OF COLLOCATION POINTS ##\n",
    "\n",
    "N_0 = 10000   ## for IC\n",
    "N_b = 10000   ## for BC\n",
    "N_r = 30000  ## for Domain\n",
    "\n",
    "\n",
    "\n",
    "############## IC setup ################\n",
    "\n",
    "# Intial conditions collocation points\n",
    "x_0 = np.random.uniform(low=xmin, high=xmax, size=(N_0,1))\n",
    "y_0 = np.random.uniform(low=ymin, high=ymax, size=(N_0,1))\n",
    "t_0 = np.zeros((N_0,1))\n",
    "\n",
    "# Evaluate intitial condition at x_0\n",
    "rho_0 = fun_rho_0(x_0, y_0)\n",
    "v_0 = fun_v_0(x_0, y_0)\n",
    "\n",
    "#IC torch variable\n",
    "pt_x_0 = torch.from_numpy(x_0).float().to(device).requires_grad_(True)\n",
    "pt_y_0 = torch.from_numpy(y_0).float().to(device).requires_grad_(True)\n",
    "pt_t_0 = torch.from_numpy(t_0).float().to(device).requires_grad_(True)\n",
    "pt_rho_0 = torch.from_numpy(rho_0).float().to(device)\n",
    "pt_vel_0 = torch.from_numpy(v_0).float().to(device)\n",
    "\n",
    "# ## Checking the initial profiles\n",
    "# plt.scatter(x_0, rho_0,s=20, c='b', marker='o',label=\"Ini-Density\")\n",
    "# plt.scatter(x_0, v_0,s=2, c='r', marker='*',label=\"Ini-Velocity\" )\n",
    "# plt.legend()\n",
    "\n",
    "\n",
    "############## BC setup ################\n",
    "\n",
    "x_bc_l = np.hstack([xmin * np.ones((N_b, 1)), np.random.uniform(low=ymin, high=ymax, size=(N_b, 1))])\n",
    "x_bc_r = np.hstack([xmax * np.ones((N_b, 1)), np.random.uniform(low=ymin, high=ymax, size=(N_b, 1))])\n",
    "y_bc_b = np.hstack([np.random.uniform(low=xmin, high=xmax, size=(N_b, 1)), ymin * np.ones((N_b, 1))])\n",
    "y_bc_t = np.hstack([np.random.uniform(low=xmin, high=xmax, size=(N_b, 1)), ymax * np.ones((N_b, 1))])\n",
    "\n",
    "t_bc = np.random.uniform(low=tmin, high=tmax, size=(N_b,1))\n",
    "\n",
    "#BC torch variable\n",
    "pt_x_bc_l = torch.from_numpy(x_bc_l).float().to(device).requires_grad_(True)\n",
    "pt_x_bc_r = torch.from_numpy(x_bc_r).float().to(device).requires_grad_(True)\n",
    "pt_y_bc_b = torch.from_numpy(y_bc_b).float().to(device).requires_grad_(True)\n",
    "pt_y_bc_t = torch.from_numpy(y_bc_t).float().to(device).requires_grad_(True)\n",
    "\n",
    "pt_t_bc = torch.from_numpy(t_bc).float().to(device).requires_grad_(True)\n",
    "\n",
    "\n",
    "############## PDE setup ################\n",
    "\n",
    "\n",
    "x_collocation = np.random.uniform(low=xmin, high=xmax, size=(N_r,1))\n",
    "y_collocation = np.random.uniform(low=ymin, high=ymax, size=(N_r,1))\n",
    "t_collocation = np.random.uniform(low=tmin, high=tmax, size=(N_r,1))\n",
    "\n",
    "#as torch variable\n",
    "pt_x_collocation = torch.from_numpy(x_collocation).float().to(device).requires_grad_(True)\n",
    "pt_y_collocation = torch.from_numpy(y_collocation).float().to(device).requires_grad_(True)\n",
    "pt_t_collocation = torch.from_numpy(t_collocation).float().to(device).requires_grad_(True)\n",
    "\n",
    "print(np.shape(pt_x_collocation))\n",
    "\n",
    "# Move the neural network to the correct device\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12afa4e-94c9-4603-80d9-d99e61c19226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:00<00:22,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL LOSS =3.96e+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [00:03<00:02, 16.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL LOSS =2.32e+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 15.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:Adam training done LBFGS initiated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:01<02:34,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL LOSS =2.03e+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [02:23<02:34,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL LOSS =3.35e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:08<00:00,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time = 314.8372778892517 sec \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "iterations = 200\n",
    "start = time.time()\n",
    "def closure():\n",
    "\n",
    "        ############## Loss based on initial conditions ###############\n",
    "\n",
    "        net_ic_out = net(torch.cat([pt_x_0, pt_y_0], dim=1), pt_t_0) # output of rho(x,t=0), vel(x,t=0)\n",
    "\n",
    "        rho_ic_out = net_ic_out[:,0:1]\n",
    "        vel_x_ic_out = net_ic_out[:,1:2]\n",
    "        vel_y_ic_out = net_ic_out[:, 2:3]\n",
    "\n",
    "        mse_rho_ic =  mse_cost_function(rho_ic_out, pt_rho_0)\n",
    "        mse_vel_x_ic =  mse_cost_function(vel_x_ic_out, pt_vel_0)\n",
    "        mse_vel_y_ic =  mse_cost_function(vel_y_ic_out, pt_vel_0)\n",
    "\n",
    "        ############# Loss based on boundary conditions #################\n",
    "\n",
    "        (\n",
    "            rho_b_x, rho_b_y,\n",
    "            vel_b_x_x, vel_b_x_y,\n",
    "            vel_b_y_x, vel_b_y_y,\n",
    "            phi_b_x, phi_b_y,\n",
    "            phi_x_x_b, phi_y_y_b\n",
    "        ) = get_boundary_rho_vel_phi(pt_x_bc_l, pt_x_bc_r, pt_y_bc_b, pt_y_bc_t, pt_t_bc, net)\n",
    "\n",
    "\n",
    "        mse_bc_rho_x = torch.mean(rho_b_x ** 2)\n",
    "        mse_bc_rho_y = torch.mean(rho_b_y ** 2)\n",
    "        mse_bc_vel_x_x = torch.mean(vel_b_x_x ** 2)\n",
    "        mse_bc_vel_x_y = torch.mean(vel_b_x_y ** 2)\n",
    "        mse_bc_vel_y_x = torch.mean(vel_b_y_x ** 2)\n",
    "        mse_bc_vel_y_y = torch.mean(vel_b_y_y ** 2)\n",
    "        mse_bc_phi_x = torch.mean(phi_b_x ** 2)\n",
    "        mse_bc_phi_y = torch.mean(phi_b_y ** 2)\n",
    "        mse_bc_phi_x_x = torch.mean(phi_x_x_b ** 2)\n",
    "        mse_bc_phi_y_y = torch.mean(phi_y_y_b ** 2)\n",
    "\n",
    "        ############## Loss based on PDE ###################################\n",
    "\n",
    "        rho_r, v_x_r, v_y_r, phi_r = pde_residue(pt_x_collocation, pt_y_collocation, pt_t_collocation, net) # output of rho(x,t) and vel(x,t)\n",
    "\n",
    "\n",
    "        mse_rho = torch.mean(rho_r ** 2) \n",
    "        mse_vel_x = torch.mean(v_x_r ** 2)\n",
    "        mse_vel_y = torch.mean(v_y_r ** 2)\n",
    "        mse_phi = torch.mean(phi_r ** 2)\n",
    "\n",
    "        ################### Combining the loss functions ####################\n",
    "        loss = (\n",
    "            mse_rho_ic + mse_vel_x_ic + mse_vel_y_ic +  # Initial conditions\n",
    "            mse_rho + mse_vel_x + mse_vel_y + mse_phi +  # PDE residuals\n",
    "            mse_bc_rho_x + mse_bc_rho_y +               # Boundary: rho\n",
    "            mse_bc_vel_x_x + mse_bc_vel_x_y +           # Boundary: vel_x\n",
    "            mse_bc_vel_y_x + mse_bc_vel_y_y +           # Boundary: vel_y\n",
    "            mse_bc_phi_x + mse_bc_phi_y +               # Boundary: phi gradients\n",
    "            mse_bc_phi_x_x + mse_bc_phi_y_y             # Boundary: phi 2nd derivatives\n",
    "        )\n",
    "        optimizerL.zero_grad()\n",
    "        loss.backward() # This is for computing gradients using backward propagationerivative of J w.r.t theta\n",
    "        return loss\n",
    "TOTAL_loss = []\n",
    "\n",
    "## Using ADAM \n",
    "\n",
    "for i in tqdm(range(iterations)): \n",
    "    loss_ = optimizer.step(closure)\n",
    "    TOTAL_loss.append(loss_.item())\n",
    "    if i % 50 == 0:\n",
    "        print(\"TOTAL LOSS ={:.2e}\".format(loss_.item()))\n",
    "print(\"INFO:Adam training done LBFGS initiated\")       \n",
    "## Using LBFGS after the initial ADAM training\n",
    "for i in tqdm(range(iterations)): \n",
    "    loss_ = optimizerL.step(closure)\n",
    "    TOTAL_loss.append(loss_.item())\n",
    "    if i % 50 == 0:\n",
    "        print(\"TOTAL LOSS ={:.2e}\".format(loss_.item()))\n",
    "end = time.time()\n",
    "print(\"Total time = {} sec \".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98ef99b-f2d1-4f4b-b7ea-dfea51159395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Plotting_2D as pt\n",
    "time_array = np.linspace(0,int(tmax),int(tmax)+3)\n",
    "initial_params = xmin, xmax, ymin, ymax, rho_1a, alpha_x, alpha_y, lam, output_folder, tmax ## required for plotting\n",
    "pt.plot_function(net, time_array, initial_params, velocity=True,isplot =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90672b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Plotting_2D as pt\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rc('grid', linestyle='-', color='black', linewidth=0.05)\n",
    "time_array = np.asarray([0.5,tmax-0.5,tmax])\n",
    "fig, axes = plt.subplots(4, 3, sharex=True,  sharey='row',figsize=(12,6),gridspec_kw={'width_ratios':[1,1,1], 'height_ratios':[3,1.2,3,1.2]})\n",
    "plt.subplots_adjust(wspace=0.12, hspace=0.1)\n",
    "initial_params = xmin,xmax,ymin,ymax,rho_1,alpha,lam,output_folder,tmax ## Params for pl\n",
    "for time,j in zip(time_array,range(3)):\n",
    "    X,rho_pred0,v_pred0,phi_pred0,rho_max_PN,rho_theory = pt.plot_function(net,time,initial_params,velocity=True,isplot = False, animation = True)\n",
    "    axes[0][j].plot(X,rho_pred0,color='c',linewidth=5,label=\"PN\")    \n",
    "    axes[0][j].plot(x,rho_LT,linestyle='dashed',color ='firebrick',linewidth=3,label=\"LT\")\n",
    "    axes[0][j].plot(x,rho,linestyle='solid',color = 'black',linewidth=1.0,label=\"FD\")\n",
    "    axes[0][j].set_xlim(xmin,xmax)\n",
    "    \n",
    "    axes[0][j].set_title(\"Time={}\".format(round(time,2)))\n",
    "    axes[0][0].set_ylabel(r\"$\\rho$\",fontsize = 18)\n",
    "    # axes[0][j].set_xlabel(\"x\",fontsize = 18)\n",
    "    axes[0][j].grid(\"True\")\n",
    "    axes[0][j].minorticks_on()\n",
    "    axes[0][j].tick_params(labelsize=10)\n",
    "    axes[0][j].tick_params(axis='both', which='major',length=4, width=2)\n",
    "    axes[0][j].tick_params(axis='both', which='minor',length=2, width=1)\n",
    "    limu = 1.2*rho_o\n",
    "    liml = .8*rho_o\n",
    "    axes[0][j].set_ylim(liml,limu)\n",
    "    axes[0][2].legend(loc='best',fancybox=False, shadow=False, ncol=3,fontsize = 10)\n",
    "    axes[0][0].text(0.42, 0.82, r\"$\\rho_1$ = {}, $\\lambda$ = {} $\\lambda_J$ \".format(rho_1,round(lam/(2*np.pi),2)),fontsize = 12, horizontalalignment='center', verticalalignment='center', transform=axes[0][0].transAxes) \n",
    "\n",
    "    \n",
    "    axes[1][j].plot(X,(rho_pred0[:,0]- rho)/((rho_pred0[:,0]+ rho)/2)*100,color = 'black',linewidth=1,label=\"FD\")\n",
    "    # axes[1][j].plot(x,(rho_pred0.flatten()-rho_LT.flatten())/((rho_pred0.flatten()+ rho_LT.flatten())/2)*100,color = 'firebrick',linestyle='dashed',linewidth=1,label=\"LT\")\n",
    "    # axes[1][j].plot(x,(rho_pred0[:,0]- rho[n-1,:])/((rho_pred0[:,0]+ rho[n-1,:])/2)*100,color = 'k',linewidth=1,label=\"FD\")\n",
    "    axes[1][j].plot(X,(rho_pred0[:,0]-rho_LT)/((rho_pred0[:,0]+ rho_LT)/2)*100,color = 'b',linewidth=1,label=\"LT\")\n",
    "    axes[1][j].set_xlabel(\"x\",fontsize = 18)\n",
    "    axes[1][j].grid(\"True\")\n",
    "    axes[1][j].minorticks_on()\n",
    "    axes[1][j].tick_params(labelsize=10)\n",
    "    axes[1][j].tick_params(axis='both', which='major',length=4, width=2)\n",
    "    axes[1][j].tick_params(axis='both', which='minor',length=2, width=1.)\n",
    "    axes[1][2].legend(loc='best',fancybox=False, shadow=False, ncol=3,fontsize = 10)\n",
    "    # axes[1][0].set_ylabel(r\"$\\rho_{PN}- \\rho_{FD or LT}/(0.5 (\\times\\rho_{PN}+ \\rho_{FD or LT}))$\",fontsize = 10)\n",
    "    axes[1][j].set_ylim(-2.0,2.0)\n",
    "    axes[1][j].set_xlim(xmin,xmax)\n",
    "    axes[1][0].set_ylabel(r\"Rel misfit $\\%$ \",fontsize = 14)\n",
    "    \n",
    "    \n",
    "    ### VELOCITY PART ######\n",
    "   \n",
    "    axes[2][j].plot(X,v_pred0,color='c',linewidth=5,label=\"PN\")    \n",
    "    axes[2][j].plot(X,v_LT,linestyle='dashed',color ='firebrick',linewidth=3,label=\"LT\")\n",
    "    axes[2][j].plot(x,v,linestyle='solid',color = 'black',linewidth=1.0,label=\"FD\")\n",
    "    \n",
    "    \n",
    "    # axes[3][j].set_title(\"Time={}\".format(round(time,2)))\n",
    "    axes[2][0].set_ylabel(r\"$v$\",fontsize = 18)\n",
    "    # axes[0][j].set_xlabel(\"x\",fontsize = 18)\n",
    "    axes[2][j].grid(\"True\")\n",
    "    axes[2][j].minorticks_on()\n",
    "    axes[2][j].tick_params(labelsize=8)\n",
    "    axes[2][j].tick_params(axis='both', which='major',length=2, width=1)\n",
    "    axes[2][j].tick_params(axis='both', which='minor',length=1, width=1)\n",
    "    # limu = 1.15*v_o\n",
    "    # liml = .85*v_o\n",
    "    # axes[0][j].set_ylim(liml,limu)\n",
    "    axes[2][2].legend(loc='best',fancybox=False, shadow=False, ncol=3,fontsize = 10)\n",
    "    \n",
    "#     axes[2][j].set_xlim(xmin,xmax)\n",
    "#     axes[2][j].set_ylim(-0.6,0.6)\n",
    "    \n",
    "    \n",
    "    axes[3][j].plot(x,(v_pred0[:,0]+1- (v+1))/((v_pred0[:,0]+1+ v+1)/2)*100,color = 'black',linewidth=1,label=\"FD\")\n",
    "    axes[3][j].plot(x,(v_pred0[:,0]+1- (v_LT+1))/((v_pred0[:,0]+1+ (v_LT+1))/2)*100,color = 'b',linewidth=1,label=\"LT\")\n",
    "    axes[3][j].set_xlabel(\"x\",fontsize = 18)\n",
    "    axes[3][j].grid(\"True\")\n",
    "    axes[3][j].minorticks_on()\n",
    "    axes[3][j].tick_params(labelsize=8)\n",
    "    axes[3][j].tick_params(axis='both', which='major',length=2, width=1)\n",
    "    axes[3][j].tick_params(axis='both', which='minor',length=1, width=1.)\n",
    "    axes[3][2].legend(loc='best',fancybox=False, shadow=False, ncol=3,fontsize = 10)\n",
    "    # axes[1][0].set_ylabel(r\"$\\rho_{PN}- \\rho_{FD or LT}/(0.5 (\\times\\rho_{PN}+ \\rho_{FD or LT}))$\",fontsize = 10)\n",
    "    axes[3][0].set_ylabel(r\"$\\epsilon$ \",fontsize = 18)\n",
    "    axes[3][j].set_ylim(-1,1)\n",
    "    axes[3][j].set_xlim(xmin,xmax)\n",
    "    \n",
    "    \n",
    "plt.savefig(output_folder+'/complete'+str(lam)+'_'+str(num_of_waves)+'_'+str(tmax)+'.png', dpi=500,bbox_inches = 'tight')\n",
    "\n",
    "# plt.show()\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
