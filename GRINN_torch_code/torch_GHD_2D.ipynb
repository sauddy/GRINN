{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f1ec247-50b3-4545-abbb-742a512903dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: not using Google CoLab\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59c3c70a-54a3-46d6-b3ff-841f7b4b0eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: Windows-11-10.0.26100-SP0\n",
      "PyTorch Version: 2.6.0+cu124\n",
      "GPU is available\n",
      "MPS (Apple Metal) is NOT AVAILABLE\n",
      "Target device is cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "## TORCH IMPORTS ##\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy.fft import fft, ifft,fft2, ifft2, fftn, ifftn\n",
    "from scipy import signal\n",
    "import os\n",
    "import scipy\n",
    "import time\n",
    "\n",
    "has_gpu = torch.cuda.is_available()\n",
    "has_mps = torch.backends.mps.is_built()\n",
    "device = \"mps\" if torch.backends.mps.is_built() \\\n",
    "    else \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "# print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(\"GPU is\", \"available\" if has_gpu else \"NOT AVAILABLE\")\n",
    "print(\"MPS (Apple Metal) is\", \"AVAILABLE\" if has_mps else \"NOT AVAILABLE\")\n",
    "print(f\"Target device is {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8565e048-302a-4d4b-a99c-e3f6583ecbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sin(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return torch.sin(input)\n",
    "    \n",
    "class PINNs(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, num_layer):\n",
    "        super(PINNs, self).__init__()\n",
    "   \n",
    "\n",
    "        layers = []\n",
    "        for i in range(num_layer-1):\n",
    "            if i == 0:\n",
    "                layers.append(nn.Linear(in_features=in_dim, out_features=hidden_dim))\n",
    "                layers.append(Sin())\n",
    "                # layers.append(torch.sin(layers))\n",
    "            else:\n",
    "                layers.append(nn.Linear(in_features=hidden_dim, out_features=hidden_dim))\n",
    "                layers.append(Sin())\n",
    "\n",
    "        layers.append(nn.Linear(in_features=hidden_dim, out_features=out_dim))\n",
    "\n",
    "        self.linear = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, y, t):\n",
    "        src = torch.cat((x, y, t), dim=-1)\n",
    "        return self.linear(src)\n",
    "    \n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d45fc50-e1b7-47f8-aed2-b9c56457c90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PINNs(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=32, bias=True)\n",
      "    (1): Sin()\n",
      "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (3): Sin()\n",
      "    (4): Linear(in_features=32, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = PINNs(in_dim=3, hidden_dim=32, out_dim=4, num_layer=3).to(device) #Input dimensions increased from 2 to 3 and Output dimensions from 3 to 4 to account for the increased spatial dimension (y)\n",
    "net.apply(init_weights)\n",
    "print(net) \n",
    "mse_cost_function = torch.nn.MSELoss() # Mean squared error\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.001,)\n",
    "optimizerL = torch.optim.LBFGS(net.parameters(),line_search_fn='strong_wolfe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4140684-1653-4ca8-a9f1-05ce01595c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary_rho_vel_phi(x_bc_l, x_bc_r, y_bc_l, y_bc_r, t, net):\n",
    "\n",
    "    rho_l, vel_l_x, vel_l_y, phi_l = net(x_bc_l,y_bc_l,t)[:,0:1], net(x_bc_l,y_bc_l,t)[:,1:2], net(x_bc_l,y_bc_l,t)[:,2:3], net(x_bc_l,y_bc_l,t)[:,3:4]\n",
    "    rho_r, vel_r_x, vel_r_y, phi_r = net(x_bc_r,y_bc_r,t)[:,0:1], net(x_bc_r,y_bc_r,t)[:,1:2], net(x_bc_r,y_bc_r,t)[:,2:3], net(x_bc_r,y_bc_r,t)[:,3:4]\n",
    "\n",
    "    '''\n",
    "    vel_l_x is the x-component of velocity at the left boundary\n",
    "    vel_l_y is the y-component of velocity at the left boundary\n",
    "    vel_r_x is the x-component of velocity at the right boundary\n",
    "    vel_r_y is the y-component of velocity at the right boundary\n",
    "    these codes are generated in the same way as rho_l, vel_l, phi_l = net(x_bc_l,t)[:,0:1], net(x_bc_l,t)[:,1:2], net(x_bc_l,t)[:,2:3] &\n",
    "    rho_r, vel_r, phi_r = net(x_bc_r,t)[:,0:1], net(x_bc_r,t)[:,1:2], net(x_bc_r,t)[:,2:3]\n",
    "\n",
    "    '''\n",
    "\n",
    "    phi_l_x = torch.autograd.grad(phi_l, x_bc_l, grad_outputs=torch.ones_like(phi_l), create_graph=True)[0]\n",
    "    phi_r_x = torch.autograd.grad(phi_r, x_bc_r, grad_outputs=torch.ones_like(phi_r), create_graph=True)[0]\n",
    "\n",
    "    phi_l_y = torch.autograd.grad(phi_l, y_bc_l, grad_outputs=torch.ones_like(phi_l), create_graph=True)[0]\n",
    "    phi_r_y = torch.autograd.grad(phi_r, y_bc_r, grad_outputs=torch.ones_like(phi_r), create_graph=True)[0]\n",
    "\n",
    "    #phi_l_y is the y axis equivalent of phi_l_x\n",
    "    #phi_r_y is the y axis equivalent of phi_r_x\n",
    "\n",
    "    rho_b_x = rho_l - rho_r \n",
    "    rho_b_y = rho_l - rho_r        #The loss function of rho_b_x and rho_b_y are defined in the same way as (1/Nb)*Σ|ρθ(ti, xi, yi) - ρb(ti, xi, yi)|^2\n",
    "    vel_b_x_x = vel_l_x - vel_r_x  #The Lvxbx term (I assume it as the loss between the x velocities of the left and right boundaries)\n",
    "    vel_b_x_y = vel_l_x - vel_l_y  #The Lvxby term (I assume it as the loss between the x and y velocity of the left boundary)\n",
    "    vel_b_y_x = vel_r_y - vel_r_x  #The Lvybx term (I assume it as the loss between the y and x velocity of the right boundary)\n",
    "    vel_b_y_y = vel_l_y - vel_r_y  #The Lvyby term (I assume it as the loss between the y velocities of the left and right boundaries)\n",
    "    phi_b_x = phi_l - phi_r\n",
    "    phi_b_y = phi_l = phi_r        #The loss function of phi_b_x and phi_b_y are defined in the same way as (1/Nb)*Σ|φθ(ti, xi, yi) - φb(ti, xi, yi)|^2\n",
    "    phi_x_x_b = phi_l_x - phi_r_x  \n",
    "    phi_y_y_b = phi_l_y - phi_r_y  #Losses associated with dφ in x and y directions\n",
    "\n",
    "    return rho_b_x, rho_b_y, vel_b_x_x, vel_b_x_y, vel_b_y_x, vel_b_y_y, phi_b_x , phi_b_y, phi_x_x_b, phi_y_y_b\n",
    "\n",
    "def pde_residue(x, y, t, net):\n",
    "\n",
    "    net_outputs = net(x,y,t)\n",
    "    \n",
    "    rho, v_x, v_y, phi = net_outputs[:,0:1], net_outputs[:,1:2], net_outputs[:,2:3], net_outputs[:,3:4]\n",
    "\n",
    "    rho_x = torch.autograd.grad(rho, x,grad_outputs=torch.ones_like(rho), create_graph=True)[0]\n",
    "    rho_y = torch.autograd.grad(rho, y,grad_outputs=torch.ones_like(rho), create_graph=True)[0]\n",
    "    rho_t = torch.autograd.grad(rho, t,grad_outputs=torch.ones_like(rho),create_graph=True)[0]\n",
    "\n",
    "    v_x_x = torch.autograd.grad(v_x, x,grad_outputs=torch.ones_like(v_x), create_graph=True)[0]\n",
    "    v_x_y = torch.autograd.grad(v_x, y,grad_outputs=torch.ones_like(v_x), create_graph=True)[0]\n",
    "    v_y_x = torch.autograd.grad(v_y, x,grad_outputs=torch.ones_like(v_y), create_graph=True)[0]\n",
    "    v_y_y = torch.autograd.grad(v_y, y,grad_outputs=torch.ones_like(v_y), create_graph=True)[0]\n",
    "    \n",
    "    v_x_t = torch.autograd.grad(v_x, t,grad_outputs=torch.ones_like(v_x), create_graph=True)[0]\n",
    "    v_y_t = torch.autograd.grad(v_y, t,grad_outputs=torch.ones_like(v_y), create_graph=True)[0]\n",
    "\n",
    "    phi_x = torch.autograd.grad(phi, x,grad_outputs=torch.ones_like(phi), create_graph=True)[0]\n",
    "    phi_x_x = torch.autograd.grad(phi_x, x,grad_outputs=torch.ones_like(phi_x), create_graph=True)[0]\n",
    "\n",
    "    phi_y = torch.autograd.grad(phi, y,grad_outputs=torch.ones_like(phi), create_graph=True)[0]\n",
    "    phi_y_y = torch.autograd.grad(phi_y, y,grad_outputs=torch.ones_like(phi_y), create_graph=True)[0]\n",
    "\n",
    "    rho_r = rho_t + v_x * rho_x + rho * v_x_x + v_y * rho_y + rho * v_y_y #The residue from the density equation, in the same format as in PINN-2DG\n",
    "    v_x_r = rho * v_x_t + rho * (v_x * v_x_x + v_y * v_x_y) + cs * cs * rho_x + rho * phi_x #The momentum equation in 2D in X, in the same format as in PINN-2DG\n",
    "    v_y_r = rho * v_y_t + rho * (v_y * v_y_y + v_x * v_y_x) + cs * cs * rho_y + rho * phi_y #The momentum equation in 2D in Y, in the same format as in PINN-2DG\n",
    "    phi_r = phi_x_x + phi_y_y - const * (rho - rho_o) #The residue from the Poisson equation, in the same format as in PINN-2DG\n",
    "\n",
    "    return rho_r, v_x_r, v_y_r, phi_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ed4e1d9-ca48-44c6-bbf0-3d2b80d446aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CASE 1           (refer to the paper for details)\n",
    "lam = 7.0           # one wavelength\n",
    "num_of_waves = 2\n",
    "rho_1 = 0.03        # question 2a linear wave propagation\n",
    "\n",
    "# ## CASE 2          (refer to the paper for details)\n",
    "# lam = 7.0          # one wavelength\n",
    "# num_of_waves = 3\n",
    "# rho_1 = 0.3        # question 2a linear wave propagation\n",
    "\n",
    "# ## CASE 2          (refer to the paper for details)\n",
    "# lam = 5.0          # one wavelength\n",
    "# num_of_waves = 3\n",
    "# rho_1 = 0.03       # question 2a linear wave propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62624d30-aa86-45ba-a2ed-1976e2616ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_o = 1          ## zeroth order density\n",
    "cs = 1.0           ##  Sound Speed\n",
    "const = 1          ## we set 4 pi G  to 1\n",
    "G = 1\n",
    "\n",
    "output_folder = \"2D_fig\" \n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "jeans = np.sqrt(4*np.pi**2*cs**2/(const*G*rho_o))\n",
    "\n",
    "if lam> jeans:\n",
    "    alpha = np.sqrt(const*G*rho_o-cs**2*(2*np.pi/lam)**2)\n",
    "else:\n",
    "    alpha = np.sqrt(cs**2*(2*np.pi/lam)**2 - const*G*rho_o)\n",
    "    \n",
    "# v_1 = (cs*rho_1)/rho_o                     ## velocity perturbation without gravity\n",
    "v_1  = (rho_1/rho_o) * (alpha/(2*np.pi/lam)) ## With gravity\n",
    "\n",
    "\n",
    "def fun_rho_0(x):\n",
    "    ''' Define initial condition for density Returning Eq (11a)'''\n",
    "    print('wavelength',lam)\n",
    "    rho_0 = rho_o + rho_1 * np.cos(2*np.pi*x/lam)    \n",
    "    return rho_0\n",
    "\n",
    "def fun_v_0(x):\n",
    "    '''initial condition for velocity -- Returning Eq 11b'''\n",
    "    \n",
    "    if lam > jeans:\n",
    "        v_0 = - v_1 * np.sin(2*np.pi*x/lam)## This is for sound wave ## refer to the paper for details\n",
    "    else:\n",
    "        v_0 = v_1 * np.cos(2*np.pi*x/lam)  ## This is for the gravity wave\n",
    "    return v_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f35fa2c2-e17b-41fa-92f8-32ae08361fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wavelength 7.0\n",
      "torch.Size([30000, 1]) torch.Size([30000, 1])\n"
     ]
    }
   ],
   "source": [
    "tmin = 0.\n",
    "tmax = 1.\n",
    "\n",
    "xmin = 0.\n",
    "xmax = xmin+lam*num_of_waves\n",
    "\n",
    "ymin = 0\n",
    "ymax = ymin+lam*num_of_waves\n",
    "\n",
    "cs = 1.\n",
    "\n",
    "### NUMBER OF COLLOCATION POINTS ##\n",
    "\n",
    "N_0 = 10000   ## for IC\n",
    "N_b = 10000   ## for BC\n",
    "N_r = 30000  ## for Domain\n",
    "\n",
    "\n",
    "\n",
    "############## IC setup ################\n",
    "\n",
    "# Intial conditions collocation points\n",
    "x_0 = np.random.uniform(low=xmin, high=xmax, size=(N_0,1))\n",
    "y_0 = np.random.uniform(low=xmin, high=xmax, size=(N_0,1))\n",
    "t_0 = np.zeros((N_0,1))\n",
    "\n",
    "# Evaluate intitial condition at x_0\n",
    "rho_0 = fun_rho_0(x_0)\n",
    "v_0 = fun_v_0(x_0)\n",
    "\n",
    "#IC torch variable\n",
    "pt_x_0 = Variable(torch.from_numpy(x_0).float(), requires_grad=False).to(device)\n",
    "pt_y_0 = Variable(torch.from_numpy(y_0).float(), requires_grad=False).to(device) #Initial conditions for y direction\n",
    "pt_t_0 = Variable(torch.from_numpy(t_0).float(), requires_grad=False).to(device)\n",
    "pt_rho_0 = Variable(torch.from_numpy(rho_0).float(), requires_grad=False).to(device)\n",
    "pt_vel_0 = Variable(torch.from_numpy(v_0).float(), requires_grad=False).to(device)\n",
    "\n",
    "# ## Checking the initial profiles\n",
    "# plt.scatter(x_0, rho_0,s=20, c='b', marker='o',label=\"Ini-Density\")\n",
    "# plt.scatter(x_0, v_0,s=2, c='r', marker='*',label=\"Ini-Velocity\" )\n",
    "# plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "############## BC setup ################\n",
    "\n",
    "x_bc_l = np.empty(N_b); x_bc_l.fill(xmin)\n",
    "x_bc_r = np.empty(N_b); x_bc_r.fill(xmax)\n",
    "y_bc_l = np.empty(N_b); y_bc_l.fill(ymin) #for y direction in left boundary\n",
    "y_bc_r = np.empty(N_b); y_bc_r.fill(ymax) #for y direction in right boundary\n",
    "t_bc = np.random.uniform(low=tmin, high=tmax, size=(N_b,1))\n",
    "#BC torch variable\n",
    "pt_x_bc_l = Variable(torch.from_numpy(x_bc_l.reshape(N_b,1)).float(), requires_grad=True).to(device)\n",
    "pt_x_bc_r = Variable(torch.from_numpy(x_bc_r.reshape(N_b,1)).float(), requires_grad=True).to(device)\n",
    "pt_y_bc_l = Variable(torch.from_numpy(y_bc_l.reshape(N_b,1)).float(), requires_grad=True).to(device) #for y direction in left boundary\n",
    "pt_y_bc_r = Variable(torch.from_numpy(y_bc_r.reshape(N_b,1)).float(), requires_grad=True).to(device) #for y direction in right boundary\n",
    "pt_t_bc = Variable(torch.from_numpy(t_bc).float(), requires_grad=False).to(device)\n",
    "\n",
    "\n",
    "############## PDE setup ################\n",
    "\n",
    "\n",
    "x_collocation = np.random.uniform(low=xmin, high=xmax, size=(N_r,1))\n",
    "y_collocation = np.random.uniform(low=ymin, high=ymax, size=(N_r,1)) #for y direction\n",
    "t_collocation = np.random.uniform(low=tmin, high=tmax, size=(N_r,1))\n",
    "\n",
    "#as torch variable\n",
    "pt_x_collocation = Variable(torch.from_numpy(x_collocation).float(), requires_grad=True).to(device)\n",
    "pt_y_collocation = Variable(torch.from_numpy(y_collocation).float(), requires_grad=True).to(device) #for y direction\n",
    "pt_t_collocation = Variable(torch.from_numpy(t_collocation).float(), requires_grad=True).to(device)\n",
    "print(np.shape(pt_x_collocation), np.shape(pt_y_collocation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12afa4e-94c9-4603-80d9-d99e61c19226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "iterations = 200\n",
    "start = time.time()\n",
    "def closure():\n",
    "\n",
    "        ############## Loss based on initial conditions ###############\n",
    "\n",
    "        net_ic_out = net(pt_x_0, pt_y_0, pt_t_0) # output of rho(x,t=0), vel(x,t=0)\n",
    "\n",
    "        rho_ic_out = net_ic_out[:,0:1]\n",
    "        vel_x_ic_out = net_ic_out[:,1:2]\n",
    "        vel_y_ic_out = net_ic_out[:, 2:3]\n",
    "\n",
    "        mse_rho_ic =  mse_cost_function(rho_ic_out, pt_rho_0)\n",
    "        mse_vel_x_ic =  mse_cost_function(vel_x_ic_out, pt_vel_0)\n",
    "        mse_vel_y_ic =  mse_cost_function(vel_y_ic_out, pt_vel_0)\n",
    "\n",
    "        ############# Loss based on boundary conditions #################\n",
    "\n",
    "        (\n",
    "            rho_b_x, rho_b_y,\n",
    "            vel_b_x_x, vel_b_x_y,\n",
    "            vel_b_y_x, vel_b_y_y,\n",
    "            phi_b_x, phi_b_y,\n",
    "            phi_x_x_b, phi_y_y_b\n",
    "        ) = get_boundary_rho_vel_phi(pt_x_bc_l, pt_x_bc_r, pt_y_bc_l, pt_y_bc_r, pt_t_bc, net)\n",
    "\n",
    "\n",
    "        mse_bc_rho_x = torch.mean(rho_b_x ** 2)\n",
    "        mse_bc_rho_y = torch.mean(rho_b_y ** 2)\n",
    "        mse_bc_vel_x_x = torch.mean(vel_b_x_x ** 2)\n",
    "        mse_bc_vel_x_y = torch.mean(vel_b_x_y ** 2)\n",
    "        mse_bc_vel_y_x = torch.mean(vel_b_y_x ** 2)\n",
    "        mse_bc_vel_y_y = torch.mean(vel_b_y_y ** 2)\n",
    "        mse_bc_phi_x = torch.mean(phi_b_x ** 2)\n",
    "        mse_bc_phi_y = torch.mean(phi_b_y ** 2)\n",
    "        mse_bc_phi_x_x = torch.mean(phi_x_x_b ** 2)\n",
    "        mse_bc_phi_y_y = torch.mean(phi_y_y_b ** 2)\n",
    "\n",
    "        ############## Loss based on PDE ###################################\n",
    "\n",
    "        rho_r, v_x_r, v_y_r, phi_r = pde_residue(pt_x_collocation, pt_y_collocation, pt_t_collocation, net) # output of rho(x,t) and vel(x,t)\n",
    "\n",
    "\n",
    "        mse_rho = torch.mean(rho_r ** 2) \n",
    "        mse_vel_x = torch.mean(v_x_r ** 2)\n",
    "        mse_vel_y = torch.mean(v_y_r ** 2)\n",
    "        mse_phi = torch.mean(phi_r ** 2)\n",
    "\n",
    "        ################### Combining the loss functions ####################\n",
    "        loss = (\n",
    "            mse_rho_ic + mse_vel_x_ic + mse_vel_y_ic +  # Initial conditions\n",
    "            mse_rho + mse_vel_x + mse_vel_y + mse_phi +  # PDE residuals\n",
    "            mse_bc_rho_x + mse_bc_rho_y +               # Boundary: rho\n",
    "            mse_bc_vel_x_x + mse_bc_vel_x_y +           # Boundary: vel_x\n",
    "            mse_bc_vel_y_x + mse_bc_vel_y_y +           # Boundary: vel_y\n",
    "            mse_bc_phi_x + mse_bc_phi_y +               # Boundary: phi gradients\n",
    "            mse_bc_phi_x_x + mse_bc_phi_y_y             # Boundary: phi 2nd derivatives\n",
    "        )\n",
    "        optimizerL.zero_grad()\n",
    "        loss.backward() # This is for computing gradients using backward propagationerivative of J w.r.t theta\n",
    "        return loss\n",
    "TOTAL_loss = []\n",
    "\n",
    "## Using ADAM \n",
    "\n",
    "for i in tqdm(range(iterations)): \n",
    "    loss_ = optimizer.step(closure)\n",
    "    TOTAL_loss.append(loss_.item())\n",
    "    if i % 50 == 0:\n",
    "        print(\"TOTAL LOSS ={:.2e}\".format(loss_.item()))\n",
    "print(\"INFO:Adam training done LBFGS initiated\")       \n",
    "## Using LBFGS after the initial ADAM training\n",
    "for i in tqdm(range(iterations)): \n",
    "    loss_ = optimizerL.step(closure)\n",
    "    TOTAL_loss.append(loss_.item())\n",
    "    if i % 50 == 0:\n",
    "        print(\"TOTAL LOSS ={:.2e}\".format(loss_.item()))\n",
    "end = time.time()\n",
    "print(\"Total time = {} sec \".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98ef99b-f2d1-4f4b-b7ea-dfea51159395",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import Plotting_2D as pt\n",
    "time_array = np.linspace(0,int(tmax),int(tmax)+3)\n",
    "initial_params = xmin,xmax,ymin,ymax,rho_1, alpha ,lam ,output_folder,tmax ## required for plotting\n",
    "pt.plot_function(net,time_array,initial_params,velocity=True,isplot =True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90672b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Plotting_2D as pt\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rc('grid', linestyle='-', color='black', linewidth=0.05)\n",
    "time_array = np.asarray([0.5,tmax-0.5,tmax])\n",
    "fig, axes = plt.subplots(4, 3, sharex=True,  sharey='row',figsize=(12,6),gridspec_kw={'width_ratios':[1,1,1], 'height_ratios':[3,1.2,3,1.2]})\n",
    "plt.subplots_adjust(wspace=0.12, hspace=0.1)\n",
    "initial_params = xmin,xmax,ymin,ymax,rho_1,alpha,lam,output_folder,tmax ## Params for pl\n",
    "for time,j in zip(time_array,range(3)):\n",
    "    X,rho_pred0,v_pred0,phi_pred0,rho_max_PN,rho_theory = pt.plot_function(net,time,initial_params,velocity=True,isplot = False, animation = True)\n",
    "    axes[0][j].plot(X,rho_pred0,color='c',linewidth=5,label=\"PN\")    \n",
    "    axes[0][j].plot(x,rho_LT,linestyle='dashed',color ='firebrick',linewidth=3,label=\"LT\")\n",
    "    axes[0][j].plot(x,rho,linestyle='solid',color = 'black',linewidth=1.0,label=\"FD\")\n",
    "    axes[0][j].set_xlim(xmin,xmax)\n",
    "    \n",
    "    axes[0][j].set_title(\"Time={}\".format(round(time,2)))\n",
    "    axes[0][0].set_ylabel(r\"$\\rho$\",fontsize = 18)\n",
    "    # axes[0][j].set_xlabel(\"x\",fontsize = 18)\n",
    "    axes[0][j].grid(\"True\")\n",
    "    axes[0][j].minorticks_on()\n",
    "    axes[0][j].tick_params(labelsize=10)\n",
    "    axes[0][j].tick_params(axis='both', which='major',length=4, width=2)\n",
    "    axes[0][j].tick_params(axis='both', which='minor',length=2, width=1)\n",
    "    limu = 1.2*rho_o\n",
    "    liml = .8*rho_o\n",
    "    axes[0][j].set_ylim(liml,limu)\n",
    "    axes[0][2].legend(loc='best',fancybox=False, shadow=False, ncol=3,fontsize = 10)\n",
    "    axes[0][0].text(0.42, 0.82, r\"$\\rho_1$ = {}, $\\lambda$ = {} $\\lambda_J$ \".format(rho_1,round(lam/(2*np.pi),2)),fontsize = 12, horizontalalignment='center', verticalalignment='center', transform=axes[0][0].transAxes) \n",
    "\n",
    "    \n",
    "    axes[1][j].plot(X,(rho_pred0[:,0]- rho)/((rho_pred0[:,0]+ rho)/2)*100,color = 'black',linewidth=1,label=\"FD\")\n",
    "    # axes[1][j].plot(x,(rho_pred0.flatten()-rho_LT.flatten())/((rho_pred0.flatten()+ rho_LT.flatten())/2)*100,color = 'firebrick',linestyle='dashed',linewidth=1,label=\"LT\")\n",
    "    # axes[1][j].plot(x,(rho_pred0[:,0]- rho[n-1,:])/((rho_pred0[:,0]+ rho[n-1,:])/2)*100,color = 'k',linewidth=1,label=\"FD\")\n",
    "    axes[1][j].plot(X,(rho_pred0[:,0]-rho_LT)/((rho_pred0[:,0]+ rho_LT)/2)*100,color = 'b',linewidth=1,label=\"LT\")\n",
    "    axes[1][j].set_xlabel(\"x\",fontsize = 18)\n",
    "    axes[1][j].grid(\"True\")\n",
    "    axes[1][j].minorticks_on()\n",
    "    axes[1][j].tick_params(labelsize=10)\n",
    "    axes[1][j].tick_params(axis='both', which='major',length=4, width=2)\n",
    "    axes[1][j].tick_params(axis='both', which='minor',length=2, width=1.)\n",
    "    axes[1][2].legend(loc='best',fancybox=False, shadow=False, ncol=3,fontsize = 10)\n",
    "    # axes[1][0].set_ylabel(r\"$\\rho_{PN}- \\rho_{FD or LT}/(0.5 (\\times\\rho_{PN}+ \\rho_{FD or LT}))$\",fontsize = 10)\n",
    "    axes[1][j].set_ylim(-2.0,2.0)\n",
    "    axes[1][j].set_xlim(xmin,xmax)\n",
    "    axes[1][0].set_ylabel(r\"Rel misfit $\\%$ \",fontsize = 14)\n",
    "    \n",
    "    \n",
    "    ### VELOCITY PART ######\n",
    "   \n",
    "    axes[2][j].plot(X,v_pred0,color='c',linewidth=5,label=\"PN\")    \n",
    "    axes[2][j].plot(X,v_LT,linestyle='dashed',color ='firebrick',linewidth=3,label=\"LT\")\n",
    "    axes[2][j].plot(x,v,linestyle='solid',color = 'black',linewidth=1.0,label=\"FD\")\n",
    "    \n",
    "    \n",
    "    # axes[3][j].set_title(\"Time={}\".format(round(time,2)))\n",
    "    axes[2][0].set_ylabel(r\"$v$\",fontsize = 18)\n",
    "    # axes[0][j].set_xlabel(\"x\",fontsize = 18)\n",
    "    axes[2][j].grid(\"True\")\n",
    "    axes[2][j].minorticks_on()\n",
    "    axes[2][j].tick_params(labelsize=8)\n",
    "    axes[2][j].tick_params(axis='both', which='major',length=2, width=1)\n",
    "    axes[2][j].tick_params(axis='both', which='minor',length=1, width=1)\n",
    "    # limu = 1.15*v_o\n",
    "    # liml = .85*v_o\n",
    "    # axes[0][j].set_ylim(liml,limu)\n",
    "    axes[2][2].legend(loc='best',fancybox=False, shadow=False, ncol=3,fontsize = 10)\n",
    "    \n",
    "#     axes[2][j].set_xlim(xmin,xmax)\n",
    "#     axes[2][j].set_ylim(-0.6,0.6)\n",
    "    \n",
    "    \n",
    "    axes[3][j].plot(x,(v_pred0[:,0]+1- (v+1))/((v_pred0[:,0]+1+ v+1)/2)*100,color = 'black',linewidth=1,label=\"FD\")\n",
    "    axes[3][j].plot(x,(v_pred0[:,0]+1- (v_LT+1))/((v_pred0[:,0]+1+ (v_LT+1))/2)*100,color = 'b',linewidth=1,label=\"LT\")\n",
    "    axes[3][j].set_xlabel(\"x\",fontsize = 18)\n",
    "    axes[3][j].grid(\"True\")\n",
    "    axes[3][j].minorticks_on()\n",
    "    axes[3][j].tick_params(labelsize=8)\n",
    "    axes[3][j].tick_params(axis='both', which='major',length=2, width=1)\n",
    "    axes[3][j].tick_params(axis='both', which='minor',length=1, width=1.)\n",
    "    axes[3][2].legend(loc='best',fancybox=False, shadow=False, ncol=3,fontsize = 10)\n",
    "    # axes[1][0].set_ylabel(r\"$\\rho_{PN}- \\rho_{FD or LT}/(0.5 (\\times\\rho_{PN}+ \\rho_{FD or LT}))$\",fontsize = 10)\n",
    "    axes[3][0].set_ylabel(r\"$\\epsilon$ \",fontsize = 18)\n",
    "    axes[3][j].set_ylim(-1,1)\n",
    "    axes[3][j].set_xlim(xmin,xmax)\n",
    "    \n",
    "    \n",
    "plt.savefig(output_folder+'/complete'+str(lam)+'_'+str(num_of_waves)+'_'+str(tmax)+'.png', dpi=500,bbox_inches = 'tight')\n",
    "\n",
    "# plt.show()\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
